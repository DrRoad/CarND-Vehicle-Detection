{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os\n",
    "import random\n",
    "from skimage.feature import hog\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# Create thresholded binary image\n",
    "def makeGrayImg(img, mask=None, colorspace='rgb', useChannel=0):\n",
    "    '''\n",
    "    Returns a grey image based on the following inputs\n",
    "    - mask\n",
    "    - choice of color space\n",
    "    - choice of channel(s) to use\n",
    "    '''\n",
    "    # color space conversion\n",
    "    if colorspace == 'gray':\n",
    "        cvt_img = cv2.cvtColor(img, cv2.COLOR_BGRGRAY)\n",
    "    elif colorspace == 'hsv':\n",
    "        cvt_img = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    elif colorspace == 'hls':\n",
    "        cvt_img = cv2.cvtColor(img, cv2.COLOR_BGR2HLS)\n",
    "    elif colorspace == 'lab':\n",
    "        cvt_img = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n",
    "    elif colorspace == 'luv':\n",
    "        cvt_img = cv2.cvtColor(img, cv2.COLOR_BGR2LUV)\n",
    "    elif colorspace == 'yuv':\n",
    "        cvt_img = cv2.cvtColor(img, cv2.COLOR_BGR2YUV)\n",
    "    else: \n",
    "        cvt_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # isolate channel\n",
    "    if colorspace != 'gray':\n",
    "        cvt_img = cvt_img[:,:,useChannel]     \n",
    "\n",
    "    # apply image mask\n",
    "    if mask is not None:\n",
    "        imgMask = np.zeros_like(cvt_img)    \n",
    "        ignore_mask_color = 255\n",
    "        # filling pixels inside the polygon defined by \"vertices\" with the fill color    \n",
    "        cv2.fillPoly(imgMask, mask, ignore_mask_color)\n",
    "        # returning the image only where mask pixels are nonzero\n",
    "        cvt_img = cv2.bitwise_and(cvt_img, imgMask)\n",
    "    return cvt_img\n",
    "\n",
    "\n",
    "def scaleImgValues(img, maxVal=None):\n",
    "    if maxVal==None:\n",
    "        maxVal=np.max(img)\n",
    "    return np.uint8(255*img/maxVal)\n",
    "\n",
    "\n",
    "def writeImg(img, outFile, binary=False):\n",
    "    if binary:\n",
    "        # scale to 8-bit (0 - 255)\n",
    "        img = np.uint8(255*img)\n",
    "    cv2.imwrite(outFile, img)\n",
    "    \n",
    "\n",
    "def plot3d(pixels, colors_rgb,\n",
    "        axis_labels=list(\"RGB\"), axis_limits=[(0, 255), (0, 255), (0, 255)]):\n",
    "    \"\"\"Plot pixels in 3D.\"\"\"\n",
    "\n",
    "    # Create figure and 3D axes\n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "    ax = Axes3D(fig)\n",
    "\n",
    "    # Set axis limits\n",
    "    ax.set_xlim(*axis_limits[0])\n",
    "    ax.set_ylim(*axis_limits[1])\n",
    "    ax.set_zlim(*axis_limits[2])\n",
    "\n",
    "    # Set axis labels and sizes\n",
    "    ax.tick_params(axis='both', which='major', labelsize=14, pad=8)\n",
    "    ax.set_xlabel(axis_labels[0], fontsize=16, labelpad=16)\n",
    "    ax.set_ylabel(axis_labels[1], fontsize=16, labelpad=16)\n",
    "    ax.set_zlabel(axis_labels[2], fontsize=16, labelpad=16)\n",
    "\n",
    "    # Plot pixel values with colors given in colors_rgb\n",
    "    ax.scatter(\n",
    "        pixels[:, :, 0].ravel(),\n",
    "        pixels[:, :, 1].ravel(),\n",
    "        pixels[:, :, 2].ravel(),\n",
    "        c=colors_rgb.reshape((-1, 3)), edgecolors='none')\n",
    "    return ax  # return Axes3D object for further manipulation\n",
    "\n",
    "\n",
    "def get_color_features(img, color_space='BGR', size=(32, 32)):\n",
    "    # Convert image to new color space (if specified)\n",
    "    if color_space != 'BGR':\n",
    "        if color_space == 'HSV':\n",
    "            feature_image = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "        elif color_space == 'LUV':\n",
    "            feature_image = cv2.cvtColor(img, cv2.COLOR_BGR2LUV)\n",
    "        elif color_space == 'LAB':\n",
    "            feature_image = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n",
    "        elif color_space == 'HLS':\n",
    "            feature_image = cv2.cvtColor(img, cv2.COLOR_BGR2HLS)\n",
    "        elif color_space == 'YUV':\n",
    "            feature_image = cv2.cvtColor(img, cv2.COLOR_BGR2YUV)\n",
    "        elif color_space == 'YCrCb':\n",
    "            feature_image = cv2.cvtColor(img, cv2.COLOR_BGR2YCrCb)\n",
    "        elif color_space == 'RGB':\n",
    "            feature_image = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    else: feature_image = np.copy(img)             \n",
    "    # Use cv2.resize().ravel() to create the feature vector\n",
    "    features = cv2.resize(feature_image, size).ravel() \n",
    "    # Return the feature vector\n",
    "    return features\n",
    "\n",
    "\n",
    "def get_colorHist_features(img, nbins=32, bins_range=(0, 256)):\n",
    "    '''\n",
    "    returns feature vector of all single channel histograms of the image\n",
    "    note: feature vector from greyscale image will be 1/3 the size of the feature vector of a color image\n",
    "    '''\n",
    "    # Compute the histogram of the color channels separately\n",
    "    channel1_hist = np.histogram(img[:,:,0], bins=nbins, range=bins_range)\n",
    "    if img.shape[2] != 0:\n",
    "        channel2_hist = np.histogram(img[:,:,1], bins=nbins, range=bins_range)\n",
    "        channel3_hist = np.histogram(img[:,:,2], bins=nbins, range=bins_range)\n",
    "        # Concatenate the histograms into a single feature vector\n",
    "        features = np.concatenate((channel1_hist[0], channel2_hist[0], channel3_hist[0]))\n",
    "    else:\n",
    "        features = channel1_hist[0]    \n",
    "    return features\n",
    "\n",
    "\n",
    "def get_hog_features(img, orient, pix_per_cell, cell_per_block, vis=False, feature_vec=True):\n",
    "    if vis == True:\n",
    "        features, hog_image = hog(img, orientations=orient, pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                                  cells_per_block=(cell_per_block, cell_per_block), transform_sqrt=False, \n",
    "                                  visualise=True, feature_vector=False)\n",
    "        return features, hog_image\n",
    "    else:      \n",
    "        features = hog(img, orientations=orient, pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                       cells_per_block=(cell_per_block, cell_per_block), transform_sqrt=False, \n",
    "                       visualise=False, feature_vector=feature_vec)\n",
    "        return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vehicleFolder = 'data/vehicles'\n",
    "nonVehicleFolder = 'data/non-vehicles'\n",
    "file_types = ('jpg', 'png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read in and count datasets\n",
    "files_vehicle = []\n",
    "files_nonVehicle = []\n",
    "for ext in file_types:\n",
    "    files_vehicle.extend(glob.glob('{}/**/*.{}'.format(vehicleFolder, ext), recursive=True))\n",
    "    files_nonVehicle.extend(glob.glob('{}/**/*.{}'.format(nonVehicleFolder, ext), recursive=True))\n",
    "\n",
    "img = cv2.imread(files_vehicle[0])\n",
    "imgShape = img.shape\n",
    "print('There are {} car and {} non-car images with shape {}'.format(len(files_vehicle), len(files_nonVehicle), imgShape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rand = random.randint(0, len(files_vehicle)-1)\n",
    "img = cv2.imread(files_vehicle[rand])\n",
    "\n",
    "color_spaces = ('rgb', 'hsv', 'hls', 'lab')\n",
    "fig = plt.figure()\n",
    "subplot_i = 1\n",
    "\n",
    "\n",
    "# visualize different color channels\n",
    "for clrSpace in color_spaces:\n",
    "    for channel in range(3):\n",
    "        cvtImg = makeGrayImg(img, mask=None, colorspace=clrSpace, useChannel=channel)\n",
    "        plt.subplot(6,6,subplot_i)\n",
    "        plt.imshow(cvtImg, cmap='gray')\n",
    "        plt.subplots_adjust(top=2.00)\n",
    "        plt.axis('off')\n",
    "        plt.title('{}: {}'.format(clrSpace, clrSpace[channel]))\n",
    "        subplot_i +=1\n",
    "        feature, hog_img = get_hog_features(cvtImg, 9, 8, 2,vis=True)\n",
    "        plt.subplot(6,6,subplot_i)\n",
    "        plt.imshow(hog_img, cmap='gray')\n",
    "        plt.subplots_adjust(top=2.00)\n",
    "        plt.axis('off')\n",
    "        plt.title('{} HOG'.format(clrSpace[channel]))\n",
    "        subplot_i +=1\n",
    "\n",
    "\n",
    "\n",
    "cvtImg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "plt.subplot(6,6,subplot_i)\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.title('original image')\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R,G,B all work well with HOG.  \n",
    "**L works well and seems more consistent across different lighting conditions and car colors**  \n",
    "H, S, A, B can get VERY noisy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "element counts in CSV: 72064\n"
     ]
    }
   ],
   "source": [
    "# Udacity open source dataset\n",
    "# labels are: Car, Truck, Pedestrian\n",
    "dataDir = 'data/object-detection-crowdai'\n",
    "csvData = []\n",
    "with open('{}/labels.csv'.format(dataDir), 'rt') as csvfile:\n",
    "    reader = csv.reader(csvfile, skipinitialspace=False)\n",
    "    next(reader)\n",
    "    for row in reader:\n",
    "        csvData.append( {'img': '%s\\%s' % (dataDir, row[4]), 'label': '%s' % (row[5]), 'xmin': int(row[0]), 'xmax': int(row[2]), 'ymin': int(row[1]), 'ymax': int(row[3])})\n",
    "        \n",
    "print('element counts in CSV: {}'.format(len(csvData)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- do a visual check of the all images and sort out excessive duplicates (e.g. sequence of 10s of frames following black SUV)  \n",
    "=> reduced data set from 9423 to 7901  \n",
    "\n",
    "- min/max values for bounding box are sometimes reversed (probably due to how labeler drew the box?). Have to sort that out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "invalid bounding box\n",
      "invalid bounding box\n"
     ]
    }
   ],
   "source": [
    "def inBBoxes(xMinRand, yMinRand, bboxSize, checkBBoxes):\n",
    "    for bbox in checkBBoxes:\n",
    "        h_overlaps = (xMinRand <= bbox[1]) and (xMinRand+bboxSize >= bbox[0])\n",
    "        v_overlaps = (yMinRand+bboxSize >= bbox[2]) and (yMinRand <= bbox[3])\n",
    "        if (h_overlaps and v_overlaps):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# extract car images, scaled to 64x64\n",
    "dest = 'data/vehicles/crowdai'\n",
    "files_uda = glob.glob('{}/*.jpg'.format(dataDir), recursive=False)\n",
    "# open each image in the folder in sequence and extract cars from it\n",
    "\n",
    "imgCount = 1\n",
    "for file in files_uda:\n",
    "    img = cv2.imread(file)\n",
    "    carEntryIndeces = [i for i in range(len(csvData)) if ((csvData[i]['img'] == file) & (csvData[i]['label'] == 'Car'))]\n",
    "    bboxAr = []\n",
    "    for i in carEntryIndeces:\n",
    "        # get bounding boxes\n",
    "        xmin = csvData[i]['xmin']\n",
    "        ymin = csvData[i]['ymin']\n",
    "        xmax = csvData[i]['xmax']\n",
    "        ymax = csvData[i]['ymax']\n",
    "        ySize = ymax-ymin\n",
    "        xSize = xmax-xmin\n",
    "        # if bbox is much taller than wide, ignore (too much stretching and probably just an occluded parked car)\n",
    "        #if ((xSize*1.5) >= ySize):\n",
    "            #bboxAr.append([xmin, xmax, ymin, ymax])\n",
    "        bboxAr.append([xmin, xmax, ymin, ymax])\n",
    "\n",
    "    for bbox in bboxAr:\n",
    "        try:\n",
    "            dest = 'data/vehicles/crowdai'\n",
    "            # cut out bounding box\n",
    "            bbox_img = img[bbox[2]:bbox[3],bbox[0]:bbox[1]]\n",
    "            # resize\n",
    "            bbox_img = cv2.resize(bbox_img, (64,64), 0,0)\n",
    "            # save\n",
    "            imgNumber = '{0:0>5}'.format(imgCount)\n",
    "            cv2.imwrite('{}/car_{}.jpg'.format(dest, imgNumber), bbox_img)\n",
    "            \n",
    "            # get non-vehicle image\n",
    "            dest = 'data/non-vehicles/crowdai'\n",
    "            bboxSize = random.randint(120,300)\n",
    "            xMinRand = random.randint(0, img.shape[1]-bboxSize)\n",
    "            yMinRand = random.randint(int(img.shape[0]/3), img.shape[0]-bboxSize-130)\n",
    "            while inBBoxes(xMinRand, yMinRand, bboxSize, bboxAr):\n",
    "                bboxSize = random.randint(120,300)\n",
    "                xMinRand = random.randint(0, img.shape[1]-bboxSize)\n",
    "                yMinRand = random.randint(int(img.shape[0]/3), img.shape[0]-bboxSize-130)\n",
    "            bbox_img = img[yMinRand:yMinRand+bboxSize,xMinRand:xMinRand+bboxSize]\n",
    "            # resize\n",
    "            bbox_img = cv2.resize(bbox_img, (64,64), 0,0)\n",
    "            # save\n",
    "            imgNumber = '{0:0>5}'.format(imgCount)\n",
    "            cv2.imwrite('{}/nonCar_{}.jpg'.format(dest, imgNumber), bbox_img)\n",
    "        except:\n",
    "            print('invalid bounding box')            \n",
    "        imgCount +=1\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# extract non-car (and non-truck and non-pedestrian) images\n",
    "# this needs to be random sized bounding boxes between ??x?? and ??x??. Size will depend on relation to test data image size.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
